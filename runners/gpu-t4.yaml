# T4 GPU Runner: 1x T4, 8 vCPU, 32GB RAM
# GitHub workflow usage: runs-on: pytorch-gpu-t4

apiVersion: actions.github.com/v1alpha1
kind: AutoscalingRunnerSet
metadata:
  name: gpu-t4
  namespace: arc-runners
spec:
  githubConfigUrl: "https://github.com/pytorch/pytorch"
  githubConfigSecret: github-secret
  
  runnerScaleSetName: pytorch-gpu-t4
  minRunners: 0
  maxRunners: 20
  
  runnerGroup: default
  
  template:
    spec:
      # Schedule only on T4 GPU nodes
      nodeSelector:
        nvidia.com/gpu: "true"
        nvidia.com/gpu.product: "T4"
      
      # Tolerate T4 GPU node taints
      tolerations:
        - key: nvidia.com/gpu
          value: "t4"
          effect: NoSchedule
      
      containers:
        - name: runner
          image: ghcr.io/actions/actions-runner:latest
          command: ["/home/runner/run.sh"]
          env:
            - name: RUNNER_FEATURE_FLAG_EPHEMERAL
              value: "true"
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: "compute,utility"
          resources:
            limits:
              nvidia.com/gpu: 1
              cpu: "8"
              memory: "32Gi"
            requests:
              nvidia.com/gpu: 1
              cpu: "4"
              memory: "16Gi"
          volumeMounts:
            - name: work
              mountPath: /home/runner/_work
      
      volumes:
        - name: work
          ephemeral:
            volumeClaimTemplate:
              spec:
                accessModes: ["ReadWriteOnce"]
                resources:
                  requests:
                    storage: 200Gi
                storageClassName: gp3
