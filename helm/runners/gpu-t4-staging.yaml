githubConfigUrl: "https://github.com/pytorch/pytorch-canary"
githubConfigSecret: "pytorch-arc-staging"
runnerScaleSetName: "c.pytorch-gpu-t4"

minRunners: 0
maxRunners: 20

runnerGroup: "default"

containerMode:
  type: "dind"

controllerServiceAccount:
  namespace: arc-systems
  name: arc-gha-rs-controller

listenerTemplate:
  spec:
    tolerations:
      - key: CriticalAddonsOnly
        operator: Equal
        value: "true"
        effect: NoSchedule
    containers:
      - name: listener
        resources:
          limits:
            cpu: "200m"
            memory: "256Mi"
          requests:
            cpu: "100m"
            memory: "128Mi"

template:
  spec:
    nodeSelector:
      nvidia.com/gpu: "true"
      nvidia.com/gpu.product: "T4"
    
    tolerations:
      - key: nvidia.com/gpu
        value: "t4"
        effect: NoSchedule
    
    containers:
      - name: runner
        image: ghcr.io/actions/actions-runner:latest
        command: ["/home/runner/run.sh"]
        env:
          - name: RUNNER_FEATURE_FLAG_EPHEMERAL
            value: "true"
          - name: NVIDIA_VISIBLE_DEVICES
            value: "all"
          - name: NVIDIA_DRIVER_CAPABILITIES
            value: "compute,utility"
        resources:
          limits:
            nvidia.com/gpu: 1
            cpu: "8"
            memory: "32Gi"
          requests:
            nvidia.com/gpu: 1
            cpu: "4"
            memory: "16Gi"
        volumeMounts:
          - name: work
            mountPath: /home/runner/_work
    
    volumes:
      - name: work
        ephemeral:
          volumeClaimTemplate:
            spec:
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 200Gi
              storageClassName: gp3
